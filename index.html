<!DOCTYPE html>
<meta charset="UTF-8">
<html lang="fr">
    <head>
        <title>Projet IFT3150</title>
        <link rel="stylesheet" href="style.css">

        <!-- Bootstrap (en commentaire for now mais si on en a besoin)-->
    <!--
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.7/dist/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    -->
    </head>

<body>

    <header>
        <div id="header_top">
            <h1>Verbalisation des expressions de fonctions lexicales</h1>
            <p>Viviane Binet, Alessandra Mancas</p>
            <p>(20244728), (20249098)</p>
            <p>Dans le cadre du cours IFT3150 - Prof. Philippe Langlais (A24)</p>
        </div>
        <div id="header_nav">
            <h3><a href="./index.html#enonce_projet">Énoncé du projet</a></h3>
            <h3><a href="./index.html#description">Description détaillée</a></h3>
            <h3><a href="./index.html#plan_avancement">Plan</a></h3>
            <h3><a href="./index.html#rapports_avancement">Rapports d'avancement</a></h3>
            <h3><a href="todo.html" id="todo-onglet">TODO</a></h3>
        </div>
    </header>
    
    <div id="contents">
    
        <section id="#enonce_projet">
            <h2>Énoncé du projet</h2>
                <p>Nous utilisons la ressource du Réseau lexical français (RL-fr) pour en extraire des exemples de fonctions lexicales.
                    Une fonction lexicale retourne un ensemble de mots qui une relation précisée par la fonction avec le mot en entrée.
                    Ces exemples seront de la forme "mot en input" -fonction-> "mot en output". Nous allons ensuite sélectionner certaines
                    fonctions lexicales et les verbaliser pour tester des modèles de langage.  Nous allons donner en entrée aux modèles des
                    phrases du genre "quel est le mot pour désigner le chef d'un navire", qui teste la fonction lexicale <i>chef de()</i>. 
                    Nous allons pouvoir comparer les performances des modèles de langage sur les différentes fonctions.
                    <a href= "https://www.ortolang.fr/market/lexicons/lexical-system-fr/v3.1">Réseau lexical du français RL-fr</a>

                </p>
        </section>
    
        <section id="#description">
        </section>
    
        <section id="#plan_avancement">
        </section>
    
        <section id="#rapports_avancement">
            <h2>Rapports d'avancement</h2>
            <h3>S1 - 02/09 - 08/09</h3>
            <ul>
                <li>Rencontre avec Philippe Langlais le vendredi 6</li>
                <li>Il nous a envoyé des sources préliminaires à lire pour se familiariser avec le RL-fr et la théorie Sens-Texte</li>
            </ul>
            <h3>S2 - 09/09 - 15/09</h3>
            <ul>
                <li>Lecture des documents sur la linguistique (Documentation du RL-fr, Théorie Sens-Texte)</li>
                <li>Rencontre avec Alexander Petrov: présentation du API qu'il a conçu pour manipuler les données du RL-fr</li>
            </ul>
            <h3>S3 - 16/09 - 22/09</h3>
            <ul>
                <li>Rencontre avec M.Langlais pour raffiner le sujet du projet.</li>
                <li>Avant de choisir les FL que nous voudrons verbaliser, il faut dresser tous les exemples tels qu'ils sont
                    décrits dans le texte "Les fonctions lexicales dernier cri" (Mel'čuk, Polguère 2021), c'est à dire sous
                    la forme "source => [séparateur1] exemple1 [séparateur2] exemple2 ...". </li>
                <li>Nous avons donc commencé à travailler sur l'API d'Alexander pour l'adapter à notre tâche, afin d'obtenir un
                    fichier .txt compréhensif contnenant des exemples</li>
            </ul>
            <h3>S4 - 23/09 - 29/09</h3>
                <li>Nous avons obtenu le fichier .txt voulu en modifiant les fonctions write_to_file(), get_endpoints() et
                    get_relation_name.</li>
            <h3>S5 - 30/09 - 6/10</h3>
                <ul>
                    <li>Nous avons obtenu un fichier .tsv des exemples afin de pouvoir les traiter facilement. Nous avons 
                        produit un fichier texte d'exemples aléatoires pour les fonctions lexicales les plus fréquentes.
                    </li>
                </ul>
            <h3>S6 - 07/10 - 13/10</h3>
                <ul>
                    <li>Grâce aux fichiers d'exemples aléatoires, nous pouvons maintenant entamer les tests avec les modèles
                        de langue en utilisant Ollama.
                    </li>
                    <li>
                        Création d'un script qui, pour une fonction donnée, crée un <i>template</i> pour le modèle, qui sera
                        rempli par chaque mot source qu'on souhaite évaluer. Les résultats du modèle de langue sont ensuite
                        écrits dans un fichier .csv afin qu'on les visualise par rapport aux sorties attendues. Un "success rate"
                        est également calculé pour qu'on mesure rapidement la performance du modèle sur chaque question.
                    </li>
                    <li>
                        Remarque: les réponses à chaque itération du modèle sont parfois légèrement différentes. Évidemment,
                        le RL-FR n'est pas exhaustif dans ses exemples et il se peut que pour une FL, un exemple donné soit valide
                        selon la définition de la FL mais qu'il ne soit pas inclus dans la base de données.
                        Il serait donc intéressant d'écrire des tests ou de quantifier les sorties des modèles pour voir ce qu'ils
                        couvrent et pour comparer les modèles entre eux.
                    </li>
                </ul>
            <h3>S7 - 14/10 - 20/10</h3>
                <ul>
                    <li>Début de la mi-session, alors semaine plus lente. Mais suite des tests sur différentes FLs et questions avec Ollama.</li>
                </ul>
            <h3>S8 - 21/10 - 27/10 </h3>
                <ul>
                    <li>
                        Semaine de relâche + mi-session, donc encore une fois un rythme ralenti.
                    </li>
                    <li>
                        Ollama roule très lentement sur nos deux ordinateurs, soit à cause de problèmes de réseau, soit à cause
                        des limites du matériel (~5 minutes pour 50 exemples)
                    </li>
                    <li>
                        Rencontre avec le professeur pour discuter d'optimisation et de la collecte des résultats. Il propose de
                        se renseigner sur le traitement en <i>batch</i> dans Ollama, pour éviter de lui envoyer une requête plusieurs fois.
                    </li>
                </ul>
            <h3>S9 - 28/10 - 3/11</h3>
                <ul>
                    <li>
                        Recherche sur les méthodes d'optimisation. Il semble que malgré l'option de traiter en batch un modèle avec Ollama,
                        ce dernier nécessite beaucoup de puissance de calcul (CPU, GPU). On essaie de trouver une solution ou une alternative.
                    </li>
                    <li>
                        Alternative possible: ChainForge
                    </li>
                        <ul>
                            <li>
                                Tout se passe en ligne, alors on ne prend pas en compte la machine (rend le travail plus généralisable aussi)
                            </li>
                            <li>
                                Possibilité de tester plusieurs modèles à la fois et comparer leurs sorties. Possible également de tester
                                plusieurs entrées.
                            </li>
                            <li>
                                Interface plutôt simple à utiliser et sortie du modèle affichée de manière intuitive
                            </li>
                            <li>
                                MAIS: plus difficile d'automatiser l'expérience, car pour chaque FL il faut créer des "Prompts nodes" qui
                                comprennent chaque question différente.
                            </li>
                            <li>Certes, il serait intéressant d'utiliser cet outil si le traitement en <i>batch</i> dans Ollama s'avère
                                trop coûteux. Après tout, on ne veut pas endommager nos ordinateurs. </li>
                        </ul>
                    <li>
                        Aussi, ajout d'une fonction qui permet de générer n ensembles aléatoires d'un certain nombre d'exemples
                        pour chaque FL.
                    </li>
                </ul>
                <h3> S10 - 4/11 - 10/11</h3>
                <ul>
                    <li>
                        Nous avons réussi à faire fonctionner de façon efficace le traitement en batch de Ollama. Nous pouvons donc tester
                         nos questions et obtenir des scores pour toutes les fonctions lexicales que nous traitons.
                    </li>
                    <li>
                        Les scores sont pour le moment gardés en mémoire dans des fichiers différents pour chaque fonction lexicale, mais
                        on peut quand même voir facilement quelles questions fonctionnent mieux.
                    </li>
                    <li>
                        Retrait des mots qui contiennent des chiffres ou d'autres caractères non alphabétiques des mots posés au 
                        modèle. 
                    </li>

                </ul>

                <h3> S11 - 11/11 - 17/11</h3>
                <ul>
                    <li>
                        Ajout d'exemples provenant de la ressource aux questions pour voir si on obtient des meilleurs scores. On veut 
                        retirer les mots en exemple des mots demandés au modèle pour ne pas gonfler artificiellement les scores. 
                    </li>
                    <li>
                        Méthode pour mettre toute l'information générée par les tests (les scores) dans un Dataframe, et ensuite pouvoir 
                        extraire ces informations pour présenter des statistiques pour voir quelles questions sont les meilleures, et si 
                        le score augmente avec le nombre d'exemples donnés.
                    </li>
                </ul>

               <h3> S12 - 18/11 - 24/11</h3>
                <ul>
                    <li>
                        Construction de différentes vues pour effectuer par la suite une analyse de nos résultats en utilisant Pandas.
                        <ul>
                            <li>
                                Une vue "sommaire" par FL, contenant les scores moyens pour chaque k-shot, leur variance et le texte
                                de chaque question (au lieu de simplement son index)
                            </li>
                            <li>
                                Par k-shot et parmi toutes les données, des vues avec les meilleures questions et leurs scores, variances
                                et textes respectifs.
                            </li>
                        </ul>
                    </li>
                    <li>
                        Présentation de nos résultats au professeur Langlais. Ok pour compiler le tout dans un rapport.
                    </li>
                    <li>
                        Début de la rédaction du rapport.
                    </li>
                </ul>

                <h3>S13 - 25/11 - 01/12 </h3>
                <ul>
                    <li>
                        Suite de la rédaction du rapport, créations de visualisations à partir de notre code.
                    </li>
                </ul>

                <h3>S14 à 16 - 02/12 - 20/12 </h3>
                <ul>
                    <li>Au cœur de la fin de session, suite et fin de la rédaction du rapport, nettoyage du code source.</li>
                </ul>

        </section>
    
    </div>
</body>
</html>